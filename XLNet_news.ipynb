{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>4490</td>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>8062</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>8622</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>4021</td>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>4330</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              title  \\\n",
       "0           8476                       You Can Smell Hillary’s Fear   \n",
       "1          10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2           3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3          10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4            875   The Battle of New York: Why This Primary Matters   \n",
       "...          ...                                                ...   \n",
       "6330        4490  State Department says it can't find emails fro...   \n",
       "6331        8062  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332        8622  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333        4021  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334        4330  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text label  \n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4     It's primary day in New York and front-runners...  REAL  \n",
       "...                                                 ...   ...  \n",
       "6330  The State Department told the Republican Natio...  REAL  \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
       "\n",
       "[6335 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'./news.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = list(df['title'])\n",
    "text = list(df['text'])\n",
    "news = []\n",
    "for i in range(len(title)):\n",
    "    news.append(title[i] + '.\\n' + text[i])\n",
    "labels = list(df['label'])\n",
    "labels = [0 if i == 'FAKE' else 1 for i in labels]\n",
    "data = (news, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  5068\n",
      "test size:  1267\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "news_train, news_test, labels_train, labels_test = train_test_split(news, labels, test_size = 0.2)\n",
    "train_data = (news_train, labels_train)\n",
    "test_data = (news_test, labels_test)\n",
    "\n",
    "print('train size: ', len(train_data[0]))\n",
    "print('test size: ', len(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "state = np.random.get_state()\n",
    "np.random.shuffle(train_data[0])\n",
    "np.random.set_state(state)\n",
    "np.random.shuffle(train_data[1])\n",
    "\n",
    "\n",
    "state1 = np.random.get_state()\n",
    "np.random.shuffle(test_data[0])\n",
    "np.random.set_state(state1)\n",
    "np.random.shuffle(test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
    "# print(len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Dilbert Creator Explains “How Do I Know The Emails Are That Bad?”.\n",
      "\n",
      "If you’re following the news, you know FBI Director James Comey announced that the FBI found a bunch of emails on Anthony Weiner’s laptop.\n",
      "As Dilbert Creator Scott Adams notes, there appears to be two main observations:\n",
      "1. Comey seemed pro-Clinton when he dropped the initial email case.\n",
      "2. Comey seems anti-Clinton this week because he announced a new round of investigations right before the election.\n",
      "So, how can both behaviors be explained? \n",
      "First some background from Adams on ‘The Persuasion Filter’ :\n",
      "As my regular readers know, the Persuasion Filter is related to the idea that the human brain never evolved to accurately comprehend reality . In order for us to be here today, our predecessors only needed to survive and procreate. They had no need to understand reality at any basic level. And we have no such need either. That’s why you might believe you are reincarnated from a monk and I might believe my prophet flew to heaven on a winged horse but we can both get through the day just fine. Many different interpretations of reality are good enough for survival. I like to describe reality as each person living their own movie, which works well unless our script’s conflict. When that happens, one of us goes into cognitive dissonance and rewrites our past to make the movies consistent. \n",
      "That’s how I see the world.\n",
      "Last year in this blog I suggested that the most productive and predictive way to view reality is through what I call the Persuasion Filter. That’s what I have been using to make spooky-good predictions about the election so far. And that’s what I’ll use today to give you an alternate movie about James Comey. Compare it to the movie you are running in your head and see which one better predicts the future.\n",
      "The base assumption of the Persuasion Filter is that people are irrational 90% of the time and only rarely – when no emotions are involved – truly rational. This is the reverse of the common filter for reality, in which people are assumed to be rational 90% of the time and a bit crazy 10% of the time. That’s some background for context.\n",
      "Read more here… \n",
      "So, back to Comey, Adams asks – which movie does the best job of explaining our observations and also predicting the future? \n",
      "Some say Comey is a political pawn in a rigged system. By that movie script we can explain why he dropped the initial email case. But we can’t explain why he’s acting against Clinton’s interests now. What changed?\n",
      "Well, some say Comey had to reopen the case against Clinton after discovering the Weiner laptop emails. If he failed to act, there might be a revolt at the FBI and maybe a whistleblower would come forward . But that leaves unexplained why Comey detailed to Congress how Clinton appeared to be guilty of crimes at the same time he said the FBI was dropping the case. If Comey had been protecting Clinton on the first round, he would have softened his description of her misdeeds, wouldn’t he? But he didn’t seem to hold back anything.\n",
      "And none of those hypotheses explain why the people who know Comey have high regard for his integrity. Comey also has the security of a 10-year appointment as Director, so he has a low chance of getting fired or politically influenced. That’s exactly why the job has a 10-year term. Given what we know of Comey before any of the Clinton emails, any movie that casts Comey as an ass-covering weasel is probably making a casting mistake.\n",
      "So allow me to offer an interpretation of events that casts Comey as more of a patriot and hero than an ass-covering weasel. Compare my interpretation with whatever movie you have in your head and see which one works best for explaining and predicting.\n",
      "My movie says Comey had good evidence against Clinton during the initial investigation but made a judgement call to leave the decision to the American public . For reasons of conscience, and acting as a patriot, Comey explained in clear language to the public exactly what evidence the FBI found against Clinton. The evidence looked damning because it was. Under this interpretation, Comey took a bullet to his reputation for the sake of the Republic. He didn’t want the FBI to steal this important decision away from the people, but at the same time he couldn’t let the people decide blind. So he divulged the evidence and stepped away, like the action hero who doesn’t look back at the explosion. \n",
      "In the second act of this movie, Comey learns that the Weiner laptop had emails that were so damning it would be a crime against the public to allow them to vote without first seeing a big red flag. And a flag was the best he could do because it was too early in the investigation to leak out bits and pieces of the evidence. That would violate Clinton’s rights.\n",
      "But Comey couldn’t easily raise a red flag to warn the public because it was against FBI policy to announce a criminal investigation about a candidate so close to election day. So Comey had a choice of either taking another bullet for the Republic or screwing the very country that he has spent his career protecting. \n",
      "In this movie, Comey did the hero thing. He alerted the public to the fact that the FBI found DISQUALIFYING information on the Weiner laptop. And he took a second bullet to his reputation. \n",
      "How do I know the new emails are that bad? \n",
      "I start by assuming Comey is the same man now as the one who was carefully vetted before being hired to protect the integrity of one of our most important institutions. And even Comey’s critics concede he’s smart. \n",
      "So…\n",
      "The way you know the new emails are disqualifying for Clinton is because otherwise our hero would have privately informed Congress and honored the tradition of not influencing elections. Comey is smart enough to know his options. And unless he suddenly turned rotten at his current age, he’s got the character to jump in front of a second bullet for the Republic.\n",
      "According to this movie, no matter who gets elected, we’ll eventually learn of something disqualifying in the Weiner emails.\n",
      "And we can’t say we weren’t warned. Comey took two bullets to do it. \n",
      "So compare this movie to your own movie and see which one does the best job of explaining the observed facts. And when we find out what is in the Weiner laptop emails, compare that news to my prediction that the information is disqualifying.\n",
      "The Persuasion Filter says there is no preferred reality. We all see our own movies. In my movie, Comey’s has a consistent personality from start to finish. He starts out his career as a smart, competent patriot and he later proves it by taking two bullets for the Republic. If your movie script has Comey suddenly changing his basic character for this election season, don’t expect an Oscar. \n",
      "Read more here… \n",
      "Of course if you’re a Democrat, this is all irrelevant and Comey is “A Putin puppet” (Howard Dean), “a federal law-breaker who should never have been appointed” (Harry Reid), and “a partisan, prejudiced individual” (Eric Holder)…\n",
      "NEW: Former Attorney General Holder, dozens of other former DOJ officials pen letter criticizing FBI director Comey. https://t.co/aXmWvAiFMg pic.twitter.com/FskFeDpoyE \n",
      "— ABC News (@ABC) October 31, 2016 \n",
      "\n",
      "You decide which makes more sense – Scott Adams’ “movie” or the real partisan hacks above? Delivered by The Daily Sheeple \n",
      "We encourage you to share and republish our reports, analyses, breaking news and videos ( Click for details ). \n",
      "Contributed by Zero Hedge of www.zerohedge.com . \n",
      "Token IDs: tensor([   17, 18853,  5500,  9795,  6527,   221,  7336,   112,    17,   150,\n",
      "          175,    18, 13992,    41,    29,   948,  1347,     9,   108,    44,\n",
      "          165,    88,   405,    18,   546,    19,    44,   175,  2830,  2731,\n",
      "          748, 10243,   202,   280,   117,   709,    29,    18,  2830,  2731,\n",
      "          255,    24,  7353,    20, 13992,    31,    48, 16539,   117,    80,\n",
      "          153,   118,   165,    23,  6575,     9,    34,    17, 18853,  5500,\n",
      "         9795,    17,    23,  9656,    24, 10976,    23,  3128,    19,   105,\n",
      "         2050,    22,    39,    87,   587, 11298,    60,   156,     9,   280,\n",
      "          117,  1395,  1284,    13, 18978,   577,    90,    43,  1695,    18,\n",
      "         2145,  1706,   363,     9,   159,     9,   280,   117,  1303,   932,\n",
      "           13, 18978,   577,    52,   260,   149,    43,   709,    24,   109,\n",
      "          866,    20,  7856,   203,   134,    18,   821,     9,   102,    19,\n",
      "          160,    64,   207, 17248,    39,  3270,     4,     3])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_input_ids = []\n",
    "train_attention_masks = []\n",
    "\n",
    "n=5068\n",
    "\n",
    "for sentence in train_data[0][:n]:\n",
    "\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        text=sentence,  # the sentence to be encoded\n",
    "        add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "        max_length = 128,  # maximum length of a sentence\n",
    "        pad_to_max_length = True,\n",
    "#         padding='max_length',  # Add [PAD]s\n",
    "        return_attention_mask = True,  # Generate the attention mask\n",
    "        return_tensors = 'pt',  # ask the function to return PyTorch tensors\n",
    "    )\n",
    "    \n",
    "    train_input_ids.append(encoded['input_ids'])\n",
    "#     print(encoded['input_ids'])\n",
    "\n",
    "    train_attention_masks.append(encoded['attention_mask'])\n",
    "\n",
    "\n",
    "train_input_ids = torch.cat(train_input_ids)\n",
    "train_attention_masks = torch.cat(train_attention_masks)\n",
    "train_labels = torch.tensor(train_data[1][:n])\n",
    "    \n",
    "\n",
    "# # Get the input IDs and attention mask in tensor format\n",
    "# input_ids = encoded['input_ids']\n",
    "# attn_mask = encoded['attention_mask']\n",
    "\n",
    "\n",
    "print('Original: ', train_data[0][0])\n",
    "print('Token IDs:', train_input_ids[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,561 training samples\n",
      "  507 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset, \n",
    "            sampler = RandomSampler(train_dataset), \n",
    "            batch_size = batch_size \n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset), \n",
    "            batch_size = batch_size \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLNetForSequenceClassification(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sequence_summary): SequenceSummary(\n",
       "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (first_dropout): Identity()\n",
       "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "\n",
    "model = XLNetForSequenceClassification.from_pretrained(\n",
    "    \"xlnet-base-cased\", \n",
    "    num_labels = 2, \n",
    "                   \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False, \n",
    "    return_dict=False\n",
    ")\n",
    "\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    286.    Elapsed: 0:00:07.\n",
      "  Batch    80  of    286.    Elapsed: 0:00:13.\n",
      "  Batch   120  of    286.    Elapsed: 0:00:20.\n",
      "  Batch   160  of    286.    Elapsed: 0:00:26.\n",
      "  Batch   200  of    286.    Elapsed: 0:00:32.\n",
      "  Batch   240  of    286.    Elapsed: 0:00:39.\n",
      "  Batch   280  of    286.    Elapsed: 0:00:45.\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    286.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    286.    Elapsed: 0:00:13.\n",
      "  Batch   120  of    286.    Elapsed: 0:00:19.\n",
      "  Batch   160  of    286.    Elapsed: 0:00:26.\n",
      "  Batch   200  of    286.    Elapsed: 0:00:32.\n",
      "  Batch   240  of    286.    Elapsed: 0:00:38.\n",
      "  Batch   280  of    286.    Elapsed: 0:00:45.\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    286.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    286.    Elapsed: 0:00:13.\n",
      "  Batch   120  of    286.    Elapsed: 0:00:19.\n",
      "  Batch   160  of    286.    Elapsed: 0:00:25.\n",
      "  Batch   200  of    286.    Elapsed: 0:00:31.\n",
      "  Batch   240  of    286.    Elapsed: 0:00:37.\n",
      "  Batch   280  of    286.    Elapsed: 0:00:44.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:45\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:02:20 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "seed_val = 42\n",
    "batch_size = 32\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "   \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "\n",
    "\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "\n",
    "        with torch.no_grad():        \n",
    "            output = model(b_input_ids, \n",
    "                                   token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "            \n",
    "\n",
    "        #total_eval_loss += loss.item()\n",
    "        logits = output[0]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # 计算准确率\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    #avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "   \n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            #'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0:00:46</td>\n",
       "      <td>0:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0:00:46</td>\n",
       "      <td>0:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0:00:45</td>\n",
       "      <td>0:00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                            \n",
       "1               0.26           0.95       0:00:46         0:00:01\n",
       "2               0.10           0.96       0:00:46         0:00:01\n",
       "3               0.04           0.97       0:00:45         0:00:01"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "\n",
    "df_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2073: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "\n",
    "n = 1267\n",
    "for sentence in test_data[0][:n]:\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        text=sentence,  # the sentence to be encoded\n",
    "        add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "        max_length = 128,  # maximum length of a sentence\n",
    "        pad_to_max_length = True,\n",
    "#         padding='max_length',  # Add [PAD]s\n",
    "        return_attention_mask = True,  # Generate the attention mask\n",
    "        return_tensors = 'pt',  # ask the function to return PyTorch tensors\n",
    "    )\n",
    "  \n",
    "    test_input_ids.append(encoded['input_ids'])\n",
    "#     print(encoded['input_ids'])\n",
    "  \n",
    "    test_attention_masks.append(encoded['attention_mask'])\n",
    "\n",
    "\n",
    "test_input_ids = torch.cat(test_input_ids)\n",
    "test_attention_masks = torch.cat(test_attention_masks)\n",
    "test_labels = torch.tensor(test_data[1][:n])\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "prediction_data = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 1,267 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    #total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "\n",
    "\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "#avg_val_accuracy = flat_accuracy(predictions, true_labels)    \n",
    "#avg_val_accuracy = total_eval_accuracy / len(prediction_dataloader)\n",
    "#print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 605 of 1267 (47.75%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (sum(test_data[1]), len(test_data[1]), (sum(test_data[1]) / len(test_data[1]) * 100.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9723756906077348"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "pred_labels_i = []\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "    pred_labels_i += list(np.argmax(predictions[i], axis=1).flatten())\n",
    "\n",
    "    \n",
    "true_labels_list = []\n",
    "for i in test_labels:\n",
    "    true_labels_list.append(i.item())\n",
    "\n",
    "accuracy_score(pred_labels_i, true_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9597    0.9835    0.9714       605\n",
      "           0     0.9845    0.9622    0.9733       662\n",
      "\n",
      "    accuracy                         0.9724      1267\n",
      "   macro avg     0.9721    0.9729    0.9723      1267\n",
      "weighted avg     0.9727    0.9724    0.9724      1267\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'POS'), Text(0, 1.5, 'NEG')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Classification Report:') \n",
    "print(classification_report(true_labels_list, pred_labels_i, labels=[1,0], digits=4)) \n",
    "\n",
    "cm = confusion_matrix(true_labels_list, pred_labels_i, labels=[1,0]) \n",
    "ax= plt.subplot() \n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\") \n",
    "ax.set_title('Confusion Matrix') \n",
    "ax.set_xlabel('Predicted Labels') \n",
    "ax.set_ylabel('True Labels') \n",
    "ax.xaxis.set_ticklabels(['POS', 'NEG']) \n",
    "ax.yaxis.set_ticklabels(['POS', 'NEG']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
